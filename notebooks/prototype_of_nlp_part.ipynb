{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153c923-f646-4978-b194-57c4953a891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from typing import Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3eabb-bbdb-4f53-b2ba-f38aec4dfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPEN_AI_KEY=os.environ.get('OPEN_AI_KEY')\n",
    "ORGANISATION_ID=os.environ.get('ORGANISATION_ID')\n",
    "PROJECT_ID=os.environ.get('PROJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557e1b9-5d6d-4b26-ab9e-7306149cbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_without_extension(file_path: str) -> str:\n",
    "\n",
    "    base_name = os.path.basename(file_path)\n",
    "    file_name, _ = os.path.splitext(base_name)\n",
    "    \n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad6ccdb-301e-46fa-bf2a-0932212497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-3.5-turbo' # gpt-4o\n",
    "\n",
    "HOME_DIR = '/usr/src/app'\n",
    "\n",
    "MESSAGES_DIR = f'{HOME_DIR}/resources/system_messages'\n",
    "SYSTEM_MESSAGE_PATH = f'{MESSAGES_DIR}/SYSTEM_MESSAGE_2.txt'\n",
    "\n",
    "EXCEL_PATH = f'{HOME_DIR}/data/sample_data.xlsx'\n",
    "\n",
    "REQUIRED_KEYS= [\"is_news\", \"is_in_country\", \"is_in_risk_category\", \"is_commodity\", \"summary\"]\n",
    "\n",
    "OUTPUT_FILEPATH = f'{HOME_DIR}/data/nlp/{MODEL.replace(\"-\", \"_\")}_{get_filename_without_extension(SYSTEM_MESSAGE_PATH)}.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb827aa-e16f-441d-8334-0529cad1377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=OPEN_AI_KEY, \n",
    "    organization=ORGANISATION_ID, \n",
    "    project=PROJECT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77426583-25aa-434a-85bb-fb91fee6911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "    prompt: str,\n",
    "    system_message: str = \"You are a helpful assistant.\",\n",
    "    model: str = \"gpt-4o\",\n",
    "    temperature: float = 0.3,\n",
    "    top_p: Union[float, int] = 1,\n",
    "    response_format_type: str = 'json_object',\n",
    ") -> Union[str, dict]:\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        response_format={\"type\": response_format_type},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3fcc3-83f6-4b73-a5f0-ce9c86329e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unixtime_to_datetime(unixtime: Union[int, float]) -> str:\n",
    "    \"\"\"Converts Unix time to a datetime object with seconds precision.\"\"\"\n",
    "    return datetime.fromtimestamp(unixtime).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bfd196-350b-4fca-a69b-0789a29a3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_system_message(system_message_path: str) -> str: \n",
    "    with open(system_message_path, 'r') as file:\n",
    "        system_message = file.read()\n",
    "\n",
    "    return system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6019d499-95fd-4db1-9987-0cbccb1e90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_nlp_part(web_scrapping_results: pd.DataFrame, \n",
    "                     system_message:str, \n",
    "                     model:str, \n",
    "                     required_keys: List[str], \n",
    "                     temperature: float = 0.3, \n",
    "                     top_p: Union[float, int] = 1, \n",
    "                     response_format_type: str = 'json_object') -> List[List[str]]:\n",
    "    \n",
    "    result=[]\n",
    "    \n",
    "    for row in web_scrapping_results.itertuples(index=True, name='Pandas'):\n",
    "        prompt = json.dumps({\n",
    "            'country':row.country, \n",
    "            'commodity':row.commodity, \n",
    "            'text':row.article_clean_text\n",
    "        })\n",
    "    \n",
    "        res = get_completion(system_message, prompt, model, temperature, top_p, response_format_type)\n",
    "        choice = res.choices[0]\n",
    "        text_output = json.loads(choice.message.content)\n",
    "    \n",
    "        social_risk_analysis_results = {key: None for key in required_keys}\n",
    "        social_risk_analysis_results['bad_response'] = None\n",
    "        \n",
    "        openai_response_metadata = {\n",
    "            'openai_response_status': choice.finish_reason,\n",
    "            'model': res.model,\n",
    "            'created': convert_unixtime_to_datetime(res.created),\n",
    "            'prompt_token_count': res.usage.prompt_tokens,\n",
    "            'completion_tokens': res.usage.completion_tokens,\n",
    "            'total_tokens': res.usage.total_tokens\n",
    "        }\n",
    "    \n",
    "        something_went_wrong = False\n",
    "    \n",
    "        if choice.finish_reason == \"stop\":\n",
    "            for key in required_keys:\n",
    "                if key not in text_output.keys():\n",
    "                    something_went_wrong = True \n",
    "                    social_risk_analysis_results[key] = 'key_not_present'\n",
    "                else:\n",
    "                    social_risk_analysis_results[key] = text_output[key]\n",
    "    \n",
    "            if something_went_wrong: \n",
    "                social_risk_analysis_results['bad_response']=text_output\n",
    "        else:\n",
    "            social_risk_analysis_results['bad_response']=text_output\n",
    "    \n",
    "        result.append([\n",
    "            *list(social_risk_analysis_results.values()),\n",
    "            openai_response_metadata['openai_response_status'],\n",
    "            openai_response_metadata['model'], \n",
    "            openai_response_metadata['created'], \n",
    "            openai_response_metadata['prompt_token_count'], \n",
    "            openai_response_metadata['completion_tokens'], \n",
    "            openai_response_metadata['total_tokens']\n",
    "        ])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7c650-ee9d-49f8-9816-6aca47e0b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(web_scrapping_results: pd.DataFrame, \n",
    "                  nlp_results: List[List[str]], \n",
    "                  required_keys: List[str],\n",
    "                  output_filepath: str\n",
    "                 ) -> pd.DataFrame: \n",
    "    \n",
    "    nlp_schema = required_keys + ['bad_response'] + ['openai_response_status', 'model', 'created', 'prompt_token_count', 'completion_tokens', 'total_tokens']\n",
    "\n",
    "    nlp_results_df = pd.DataFrame(nlp_results, columns=nlp_schema)\n",
    "\n",
    "    web_scrap_and_nlp_df = pd.concat([web_scrapping_results, nlp_results_df], axis=1)\n",
    "\n",
    "    web_scrap_and_nlp_df.to_excel(output_filepath, index=False)\n",
    "\n",
    "    return web_scrap_and_nlp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0e07a-3cd0-488e-965d-e7e2fcd1d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_message = read_system_message(SYSTEM_MESSAGE_PATH)\n",
    "web_scrapping_results = pd.read_excel(EXCEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb70fad-d07a-4c7b-b954-1053c3da8606",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nlp_results = perform_nlp_part(web_scrapping_results[:4], sys_message, MODEL, REQUIRED_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a6912-7207-4458-af85-81fff889f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = write_results(web_scrapping_results, nlp_results, REQUIRED_KEYS, OUTPUT_FILEPATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
